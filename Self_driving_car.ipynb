{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "XHFnthirwlfn"
   },
   "outputs": [],
   "source": [
    "# Credits: https://github.com/SullyChen/Autopilot-TensorFlow\n",
    "# Research paper: End to End Learning for Self-Driving Cars by Nvidia. [https://arxiv.org/pdf/1604.07316.pdf]\n",
    "\n",
    "# NVidia dataset: 72 hrs of video => 72*60*60*30 = 7,776,000 images\n",
    "# Nvidia blog: https://devblogs.nvidia.com/deep-learning-self-driving-cars/\n",
    "\n",
    "\n",
    "# Our Dataset: https://github.com/SullyChen/Autopilot-TensorFlow [https://drive.google.com/file/d/0B-KJCaaF7elleG1RbzVPZWV4Tlk/view]\n",
    "# Size: 25 minutes = 25*60*30 = 45,000 images ~ 2.3 GB\n",
    "\n",
    "\n",
    "# If you want to try on a slightly large dataset: 70 minutes of data ~ 223GB\n",
    "# Refer: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5\n",
    "# Format: Image, latitude, longitude, gear, brake, throttle, steering angles and speed\n",
    "\n",
    "\n",
    "\n",
    "# Additional Installations:\n",
    "# pip3 install h5py\n",
    "\n",
    "\n",
    "# AWS: https://aws.amazon.com/blogs/machine-learning/get-started-with-deep-learning-using-the-aws-deep-learning-ami/\n",
    "\n",
    "# Youtube:https://www.youtube.com/watch?v=qhUvQiKec2U\n",
    "# Further reading and extensions: https://medium.com/udacity/teaching-a-machine-to-steer-a-car-d73217f2492c\n",
    "# More data: https://medium.com/udacity/open-sourcing-223gb-of-mountain-view-driving-data-f6b5593fbfa5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2,3],[3,4,5]])\n",
    "print(a)\n",
    "print(a[-1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scipy.misc.imresize(scipy.misc.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0\n",
    "# you can break the whole line into parts like this\n",
    "# here (train_batch_pointer + i) % num_train_images => \"% num_train_images\" is used to make sure that the\n",
    "# (train_batch_pointer + i) values should not cross number of train images.\n",
    "import scipy\n",
    "import scipy.misc\n",
    "#from scipy.misc import imread\n",
    "import imageio\n",
    "# lets explain whats happening with the first images\n",
    "image_read = scipy.misc.imread(train_xs[0])\n",
    "print(\"original image size\",image_read.shape)\n",
    "\n",
    "print(\"After taking the last 150 rows i.e lower part of the images where road is present, \",image_read[-150:].shape)\n",
    "image_read = image_read[-150:]\n",
    "resized_image = scipy.misc.imresize(image_read, [66, 200])\n",
    "print(\"After resizing the images into 66*200, \",resized_image.shape)\n",
    "# 200/66 = 455/150 = 3.0303 => we are keeping aspect ratio when we are resizing it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imageio.imresize(simageio.imread(train_xs[0])[-150:], [66, 200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.misc\n",
    "import random\n",
    "\n",
    "xs = []\n",
    "ys = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(\"driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "\n",
    "train_xs = xs[:int(len(xs) * 0.8)]\n",
    "train_ys = ys[:int(len(xs) * 0.8)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.2):]\n",
    "val_ys = ys[-int(len(xs) * 0.2):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)\n",
    "\n",
    "def LoadTrainBatch(batch_size):\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(scipy.misc.imresize(scipy.misc.imread(val_xs[(val_batch_pointer + i) % num_val_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy\n",
    "\n",
    "def weight_variable(shape):\n",
    "  initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "  initial = tf.constant(0.1, shape=shape)\n",
    "  return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "  return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3])\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1])\n",
    "\n",
    "x_image = x\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24])\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36])\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48])\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64])\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64])\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.multiply(tf.atan(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) #scale the atan output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "vgcc6iQobKHi"
   },
   "outputs": [],
   "source": [
    "# read images and steering angles from driving_dataset folder\n",
    "\n",
    "from __future__ import division\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "from scipy import pi\n",
    "from itertools import islice\n",
    "\n",
    "\n",
    "\n",
    "DATA_FOLDER = './driving_dataset/' # change this to your folder\n",
    "TRAIN_FILE = os.path.join(DATA_FOLDER, 'data.txt')\n",
    "\n",
    "\n",
    "split =0.8\n",
    "X = []\n",
    "y = []\n",
    "with open(TRAIN_FILE) as fp:\n",
    "    for line in islice(fp, LIMIT):\n",
    "        path, angle = line.strip().split()\n",
    "        full_path = os.path.join(DATA_FOLDER, path)\n",
    "        X.append(full_path)\n",
    "        \n",
    "        # converting angle from degrees to radians\n",
    "        y.append(float(angle) * pi / 180 )\n",
    "\n",
    "\n",
    "y = np.array(y)\n",
    "print(\"Completed processing data.txt\")\n",
    "\n",
    "split_index = int(len(y)*0.8)\n",
    "\n",
    "train_y = y[:split_index]\n",
    "test_y = y[split_index:]\n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy;\n",
    "\n",
    "# PDF of train and test 'y' values. \n",
    "import matplotlib.pyplot as plt \n",
    "plt.hist(train_y, bins=50, normed=1, color='green', histtype ='step');\n",
    "plt.hist(test_y, bins=50, normed=1, color='red', histtype ='step');\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model 0: Base line Model: y_test_pred = mean(y_train_i) \n",
    "train_mean_y = np.mean(train_y)\n",
    "\n",
    "print('Test_MSE(MEAN):%f' % np.mean(np.square(test_y-train_mean_y)) )\n",
    "\n",
    "print('Test_MSE(ZERO):%f' % np.mean(np.square(test_y-0.0)) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import model\n",
    "import cv2\n",
    "from subprocess import call\n",
    "\n",
    "sess = tf.InteractiveSession()\n",
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"save/model.ckpt\")\n",
    "\n",
    "img = cv2.imread('steering_wheel_image.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "while(cv2.waitKey(10) != ord('q')):\n",
    "    ret, frame = cap.read()\n",
    "    image = scipy.misc.imresize(frame, [66, 200]) / 255.0\n",
    "    degrees = model.y.eval(feed_dict={model.x: [image], model.keep_prob: 1.0})[0][0] * 180 / scipy.pi\n",
    "    call(\"clear\")\n",
    "    print(\"Predicted steering angle: \" + str(degrees) + \" degrees\")\n",
    "    cv2.imshow('frame', frame)\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.2 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1)\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst)\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\SUNNY\\Desktop\\Autopilot\\model.py:15: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SUNNY\\Desktop\\Autopilot\\model.py:5: The name tf.truncated_normal is deprecated. Please use tf.random.truncated_normal instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\SUNNY\\Desktop\\Autopilot\\model.py:58: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import cv2\n",
    "from subprocess import call\n",
    "import math\n",
    "from tensorflow.core.protobuf import saver_pb2\n",
    "import driving_data\n",
    "import model\n",
    "import tensorflow as tf\n",
    "import scipy\n",
    "import scipy.misc\n",
    "import random\n",
    "import numpy as np\n",
    "from scipy import pi\n",
    "from itertools import islice\n",
    "#from __future__ import division\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "path=r\"C:\\Users\\SUNNY\\Desktop\\Autopilot\"\n",
    "os.chdir(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed processing data.txt\n"
     ]
    }
   ],
   "source": [
    "# read images and steering angles from driving_dataset folder\n",
    "DATA_FOLDER = './driving_dataset/' # change this to your folder\n",
    "TRAIN_FILE = os.path.join(DATA_FOLDER, 'data.txt')\n",
    "\n",
    "\n",
    "split =0.8 #This is giving the 80% Train and 20% Test Data Split\n",
    "X = []\n",
    "y = []\n",
    "with open(TRAIN_FILE) as fp: #Reading tre file\n",
    "    for line in islice(fp,None):\n",
    "        path, angle = line.strip().split()  #Reading the path and angle\n",
    "        full_path = os.path.join(DATA_FOLDER, path)\n",
    "        X.append(full_path)\n",
    "        \n",
    "        # converting angle from degrees to radians\n",
    "        y.append(float(angle) * pi / 180 )\n",
    "\n",
    "\n",
    "y = np.array(y)\n",
    "print(\"Completed processing data.txt\")\n",
    "\n",
    "# Now split the angles into train_y and test_y\n",
    "split_index = int(len(y)*0.8)\n",
    "\n",
    "train_y = y[:split_index] #First 80%\n",
    "test_y = y[split_index:] # Last 20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUNNY\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:6: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  \n",
      "C:\\Users\\SUNNY\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: MatplotlibDeprecationWarning: \n",
      "The 'normed' kwarg was deprecated in Matplotlib 2.1 and will be removed in 3.1. Use 'density' instead.\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy;\n",
    "\n",
    "# PDF of train and test 'y' values. \n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "plt.hist(train_y, bins=50, normed=1, color='green', histtype ='step');\n",
    "plt.hist(test_y, bins=50, normed=1, color='red', histtype ='step');\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = []\n",
    "ys = []\n",
    "\n",
    "#points to the end of the last batch\n",
    "train_batch_pointer = 0\n",
    "val_batch_pointer = 0\n",
    "\n",
    "#read data.txt\n",
    "with open(\"driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        #We split the text data(data.txt file) and line.split()[0] will give inage name , line.split()[1] gives angles\n",
    "        xs.append(\"driving_dataset/\" + line.split()[0]) #xs contains the path to the images.\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180) #ys contains the angles in radians\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Temporal split\n",
    "train_xs = xs[:int(len(xs) * 0.7)] \n",
    "train_ys = ys[:int(len(xs) * 0.7)]\n",
    "\n",
    "val_xs = xs[-int(len(xs) * 0.3):]\n",
    "val_ys = ys[-int(len(xs) * 0.3):]\n",
    "\n",
    "num_train_images = len(train_xs)\n",
    "num_val_images = len(val_xs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function loads batch of images from training data\n",
    "from PIL import Image\n",
    " #Image.resize\n",
    "def LoadTrainBatch(batch_size): #batch_size will give the number of images in each batch we want to pass\n",
    "    global train_batch_pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        # We will take the last 150 images where road is present\n",
    "        '''We are cropping the image to get only the lower part we analyzed the images\n",
    "        and we think like if we crop the image, we will get only road part of the image\n",
    "        and it will be useful to drive'''\n",
    "        x_out.append(Image.resize(Image.imread(train_xs[(train_batch_pointer + i) % num_train_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([train_ys[(train_batch_pointer + i) % num_train_images]])\n",
    "    train_batch_pointer += batch_size\n",
    "    return x_out, y_out\n",
    "\n",
    "# This function loads batch of images from test data\n",
    "def LoadValBatch(batch_size):\n",
    "    global val_batch_pointer #Take this global so that it remembers the pointer\n",
    "    x_out = []\n",
    "    y_out = []\n",
    "    for i in range(0, batch_size):\n",
    "        x_out.append(Image.resize(Image.imread(val_xs[(val_batch_pointer + i) % num_val_images])[-150:], [66, 200]) / 255.0)\n",
    "        y_out.append([val_ys[(val_batch_pointer + i) % num_val_images]])\n",
    "    val_batch_pointer += batch_size\n",
    "    return x_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_variable(shape):  \n",
    "    initial = tf.truncated_normal(shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "def conv2d(x, W, stride):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, stride, stride, 1], padding='VALID')\n",
    "\n",
    "x = tf.placeholder(tf.float32, shape=[None, 66, 200, 3]) # For Input variables\n",
    "y_ = tf.placeholder(tf.float32, shape=[None, 1]) \n",
    "\n",
    "x_image = x #Image dimension\n",
    "\n",
    "#first convolutional layer\n",
    "W_conv1 = weight_variable([5, 5, 3, 24]) # (5*5) kernels, 24 kernels\n",
    "b_conv1 = bias_variable([24])\n",
    "\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1, 2) + b_conv1)\n",
    "\n",
    "#second convolutional layer\n",
    "W_conv2 = weight_variable([5, 5, 24, 36]) # (5*5) kernels, 36 kernels\n",
    "b_conv2 = bias_variable([36])\n",
    "\n",
    "h_conv2 = tf.nn.relu(conv2d(h_conv1, W_conv2, 2) + b_conv2)\n",
    "\n",
    "#third convolutional layer\n",
    "W_conv3 = weight_variable([5, 5, 36, 48]) # (5*5) kernels, 48 kernels\n",
    "b_conv3 = bias_variable([48])\n",
    "\n",
    "h_conv3 = tf.nn.relu(conv2d(h_conv2, W_conv3, 2) + b_conv3)\n",
    "\n",
    "#fourth convolutional layer\n",
    "W_conv4 = weight_variable([3, 3, 48, 64]) # (3*3) kernels, 64 kernels\n",
    "b_conv4 = bias_variable([64])\n",
    "\n",
    "h_conv4 = tf.nn.relu(conv2d(h_conv3, W_conv4, 1) + b_conv4)\n",
    "\n",
    "#fifth convolutional layer\n",
    "W_conv5 = weight_variable([3, 3, 64, 64]) # (3*3) kernels, 64 kernels\n",
    "b_conv5 = bias_variable([64])\n",
    "\n",
    "h_conv5 = tf.nn.relu(conv2d(h_conv4, W_conv5, 1) + b_conv5)\n",
    "#FCL 1\n",
    "W_fc1 = weight_variable([1152, 1164])\n",
    "b_fc1 = bias_variable([1164])\n",
    "\n",
    "h_conv5_flat = tf.reshape(h_conv5, [-1, 1152]) # Flatten\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_conv5_flat, W_fc1) + b_fc1)\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "#FCL 2\n",
    "W_fc2 = weight_variable([1164, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "\n",
    "h_fc2 = tf.nn.relu(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)\n",
    "\n",
    "h_fc2_drop = tf.nn.dropout(h_fc2, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc3 = weight_variable([100, 50])\n",
    "b_fc3 = bias_variable([50])\n",
    "\n",
    "h_fc3 = tf.nn.relu(tf.matmul(h_fc2_drop, W_fc3) + b_fc3)\n",
    "\n",
    "h_fc3_drop = tf.nn.dropout(h_fc3, keep_prob)\n",
    "\n",
    "#FCL 3\n",
    "W_fc4 = weight_variable([50, 10])\n",
    "b_fc4 = bias_variable([10])\n",
    "h_fc4 = tf.nn.relu(tf.matmul(h_fc3_drop, W_fc4) + b_fc4)\n",
    "\n",
    "h_fc4_drop = tf.nn.dropout(h_fc4, keep_prob)\n",
    "\n",
    "#Output\n",
    "W_fc5 = weight_variable([10, 1])\n",
    "b_fc5 = bias_variable([1])\n",
    "\n",
    "y = tf.identity(tf.matmul(h_fc4_drop, W_fc5) + b_fc5)  \n",
    "#y = tf.multipltf.identity(tf.matmul(h_fc4_drop, W_fc5) + b_fc5), 2) \n",
    "\n",
    "# atan works better than 'linear' here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SUNNY\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\client\\session.py:1750: UserWarning: An interactive session is already active. This can cause out-of-memory errors in some cases. You must explicitly call `InteractiveSession.close()` to release resources held by the other session(s).\n",
      "  warnings.warn('An interactive session is already active. This can '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "L2NormConst = 0.001 # Lambda of L2-Regularisation\n",
    "\n",
    "train_vars = tf.trainable_variables()\n",
    "\n",
    "#!st Part is the Loss(MeanSquaredError or Reduced_mean)\n",
    "#2nd part is the Regularisation part\n",
    "loss = tf.reduce_mean(tf.square(tf.subtract(model.y_, model.y))) + tf.add_n([tf.nn.l2_loss(v) for v in train_vars]) * L2NormConst\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(loss) #Learning Rate Default =10^-3\n",
    "sess.run(tf.initialize_all_variables())\n",
    "\n",
    "# create a summary to monitor cost tensor\n",
    "tf.summary.scalar(\"loss\", loss)\n",
    "# merge all summaries into a single op\n",
    "merged_summary_op =  tf.summary.merge_all()\n",
    "\n",
    "saver = tf.train.Saver(write_version = saver_pb2.SaverDef.V1)\n",
    "\n",
    "# op to write logs to Tensorboard\n",
    "logs_path = './logs'\n",
    "summary_writer = tf.summary.FileWriter(logs_path, graph=tf.get_default_graph())\n",
    "\n",
    "epochs = 30\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Step: 0, Loss: 19.0761\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'logs' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-eddbe539b99d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m             \u001b[0mcheckpoint_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"model.ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m             \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheckpoint_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Model saved in file: %s\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'logs' is not defined"
     ]
    }
   ],
   "source": [
    "# train over the dataset about 30 times\n",
    "for epoch in range(epochs):\n",
    "    for i in range(int(driving_data.num_images/batch_size)):\n",
    "        xs, ys = driving_data.LoadTrainBatch(batch_size)\n",
    "        train_step.run(feed_dict={model.x: xs, model.y_: ys, model.keep_prob: 0.5}) #keep_prob=0.5 means , dropout=0.5\n",
    "        #After every 10 steps we will print the Epochs and Loss\n",
    "        if i % 10 == 0:\n",
    "            xs, ys = driving_data.LoadValBatch(batch_size)\n",
    "            loss_value = loss.eval(feed_dict={model.x:xs, model.y_: ys, model.keep_prob: 1.0})\n",
    "            print(\"Epoch: %d, Step: %d, Loss: %g\" % (epoch, epoch * batch_size + i, loss_value))\n",
    "\n",
    "    # write logs at every iteration\n",
    "        summary = merged_summary_op.eval(feed_dict={model.x:xs, model.y_: ys, model.keep_prob: 1.0})\n",
    "        summary_writer.add_summary(summary, epoch * driving_data.num_images/batch_size + i)\n",
    "\n",
    "        if i % batch_size == 0:\n",
    "            \n",
    "            checkpoint_path = os.path.join(logs, \"model.ckpt\")\n",
    "            filename = saver.save(sess, checkpoint_path)\n",
    "    print(\"Model saved in file: %s\" % filename)\n",
    "\n",
    "print(\"Run the command line:\\n\" \\\n",
    "          \"--> tensorboard --logdir=./logs \" \\\n",
    "          \"\\nThen open http://0.0.0.0:6006/ into your web browser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFoundError",
     "evalue": "FindFirstFile failed for: save_assignment2 : The system cannot find the path specified.\r\n; No such process",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-32-8011b55d66b0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msaver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSaver\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0msaver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrestore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"save_assignment2/model.ckpt\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mimg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'steering_wheel_image.jpg'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrows\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\saver.py\u001b[0m in \u001b[0;36mrestore\u001b[1;34m(self, sess, save_path)\u001b[0m\n\u001b[0;32m   1278\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1279\u001b[0m     \u001b[0mcheckpoint_prefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1280\u001b[1;33m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcheckpoint_management\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheckpoint_exists_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1281\u001b[0m       raise ValueError(\"The passed save_path is not a valid checkpoint: \" +\n\u001b[0;32m   1282\u001b[0m                        checkpoint_prefix)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\training\\checkpoint_management.py\u001b[0m in \u001b[0;36mcheckpoint_exists_internal\u001b[1;34m(checkpoint_prefix)\u001b[0m\n\u001b[0;32m    364\u001b[0m   pathname = _prefix_to_checkpoint_path(checkpoint_prefix,\n\u001b[0;32m    365\u001b[0m                                         saver_pb2.SaverDef.V2)\n\u001b[1;32m--> 366\u001b[1;33m   \u001b[1;32mif\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_matching_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpathname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m   \u001b[1;32melif\u001b[0m \u001b[0mfile_io\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_matching_files\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcheckpoint_prefix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mget_matching_files\u001b[1;34m(filename)\u001b[0m\n\u001b[0;32m    361\u001b[0m     \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mIf\u001b[0m \u001b[0mthere\u001b[0m \u001b[0mare\u001b[0m \u001b[0mfilesystem\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mdirectory\u001b[0m \u001b[0mlisting\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m   \"\"\"\n\u001b[1;32m--> 363\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mget_matching_files_v2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\lib\\io\\file_io.py\u001b[0m in \u001b[0;36mget_matching_files_v2\u001b[1;34m(pattern)\u001b[0m\n\u001b[0;32m    382\u001b[0m         \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_str_any\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatching_filename\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m         for matching_filename in pywrap_tensorflow.GetMatchingFiles(\n\u001b[1;32m--> 384\u001b[1;33m             compat.as_bytes(pattern))\n\u001b[0m\u001b[0;32m    385\u001b[0m     ]\n\u001b[0;32m    386\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFoundError\u001b[0m: FindFirstFile failed for: save_assignment2 : The system cannot find the path specified.\r\n; No such process"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver.restore(sess, \"save_assignment2/model.ckpt\")\n",
    "\n",
    "img = cv2.imread('steering_wheel_image.jpg',0)\n",
    "rows,cols = img.shape\n",
    "\n",
    "smoothed_angle = 0\n",
    "\n",
    "\n",
    "#read data.txt\n",
    "xs = []\n",
    "ys = []\n",
    "with open(\"driving_dataset/data.txt\") as f:\n",
    "    for line in f:\n",
    "        xs.append(\"driving_dataset/\" + line.split()[0])\n",
    "        #the paper by Nvidia uses the inverse of the turning radius,\n",
    "        #but steering wheel angle is proportional to the inverse of turning radius\n",
    "        #so the steering wheel angle in radians is used as the output\n",
    "        ys.append(float(line.split()[1]) * scipy.pi / 180)\n",
    "\n",
    "#get number of images\n",
    "num_images = len(xs)\n",
    "\n",
    "i = math.ceil(num_images*0.7)\n",
    "print(\"Starting frameofvideo:\" +str(i))\n",
    "\n",
    "while(cv2.waitKey(10) != ord('q')): ## keep running this with 10ms delay untill 'q' is pressed\n",
    "    full_image = scipy.misc.imread(\"driving_dataset/\" + str(i) + \".jpg\", mode=\"RGB\")\n",
    "    image = scipy.misc.imresize(full_image[-150:], [66, 200]) / 255.0\n",
    "    degrees = model.y.eval(feed_dict={model.x: [image], model.keep_prob: 1.0})[0][0] * 180.0 / scipy.pi\n",
    "    #call(\"clear\")\n",
    "    #print(\"Predicted Steering angle: \" + str(degrees))\n",
    "    print(\"Steering angle: \" + str(degrees) + \" (pred)\\t\" + str(ys[i]*180/scipy.pi) + \" (actual)\")\n",
    "    cv2.imshow(\"frame\", cv2.cvtColor(full_image, cv2.COLOR_RGB2BGR)) # This shows the Road Image\n",
    "    #make smooth angle transitions by turning the steering wheel based on the difference of the current angle\n",
    "    #and the predicted angle\n",
    "    smoothed_angle += 0.2 * pow(abs((degrees - smoothed_angle)), 2.0 / 3.0) * (degrees - smoothed_angle) / abs(degrees - smoothed_angle)\n",
    "    M = cv2.getRotationMatrix2D((cols/2,rows/2),-smoothed_angle,1) #Rotation of steering Wheel\n",
    "    dst = cv2.warpAffine(img,M,(cols,rows))\n",
    "    cv2.imshow(\"steering wheel\", dst) # This shows the Steering Wheel\n",
    "    i += 1\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "Self_driving_car.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
